{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from evogym.envs import *\n",
    "from evogym import EvoViewer, get_full_connectivity\n",
    "from neural_controller import NeuralController, set_weights\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(algorithm, num_runs=5, num_generations=100, scenario='DownStepper-v0', steps=500):\n",
    "    \"\"\"\n",
    "    Run an evolutionary algorithm multiple times and store key results.\n",
    "\n",
    "    Parameters:\n",
    "        algorithm (function): The function that runs an evolutionary algorithm (e.g., `evolution_strategy`).\n",
    "        num_runs (int): Number of times to run the algorithm.\n",
    "        num_generations (int): Number of generations per run.\n",
    "        scenario (str): Environment scenario.\n",
    "        steps (int): Number of steps per simulation.\n",
    "\n",
    "    Returns:\n",
    "        best_overall_weights (list): Best neural network weights found across all runs.\n",
    "        best_overall_fitness (float): Best fitness score found across all runs.\n",
    "        mean_fitness_per_generation (np.array): Mean best fitness per generation across all runs.\n",
    "        mean_fitnesses (np.array): Mean of mean fitness scores per generation.\n",
    "        mean_execution_time (float): Mean execution time across all runs.\n",
    "        std_fitnesses (np.array): Standard deviation of fitness scores per generation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize storage variables\n",
    "    best_fitnesses_overall = np.zeros(num_generations)  # Sum fitness scores across runs (to average later)\n",
    "    mean_fitnesses = np.zeros(num_generations)  # Sum mean fitness scores across runs (to average later)\n",
    "    std_fitnesses = np.zeros(num_generations)  # Sum std fitness scores across runs (to average later)\n",
    "    \n",
    "    total_execution_time = 0\n",
    "    best_overall_fitness = float('-inf')\n",
    "    best_overall_weights = None\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        print(f\"\\nRunning {algorithm.__name__} {i + 1}/{num_runs}...\")\n",
    "\n",
    "        # Run the algorithm and extract results\n",
    "        best_weights, best_fitness, best_fitness_scores, mean_fitnesses_run, execution_time, std_fitness_scores_run = algorithm()\n",
    "\n",
    "        print(f\"Best fitness score of run {i + 1}: {best_fitness:.3f}\")\n",
    "\n",
    "        # Accumulate fitness data for averaging\n",
    "        best_fitnesses_overall += np.array(best_fitness_scores)  \n",
    "        mean_fitnesses += np.array(mean_fitnesses_run)  \n",
    "        std_fitnesses += np.array(std_fitness_scores_run)\n",
    "\n",
    "        # Keep track of the best neural network controller across all runs\n",
    "        if best_fitness > best_overall_fitness:\n",
    "            best_overall_fitness = best_fitness\n",
    "            best_overall_weights = best_weights\n",
    "\n",
    "        # Accumulate execution time\n",
    "        total_execution_time += execution_time\n",
    "\n",
    "    # Compute the **mean** best fitness per generation across runs\n",
    "    best_fitnesses_overall /= num_runs\n",
    "    mean_fitnesses /= num_runs\n",
    "    std_fitnesses /= num_runs\n",
    "    mean_execution_time = total_execution_time / num_runs\n",
    "\n",
    "    print(\"\\nFinal Results After Multiple Runs:\")\n",
    "    print(f\"Mean execution time: {mean_execution_time:.2f} seconds\")\n",
    "    print(f\"Best fitness found: {best_overall_fitness:.3f}\")\n",
    "\n",
    "    # Plot averaged fitness evolution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(num_generations), best_fitnesses_overall, label=\"Best Fitness per Generation\", color='blue')\n",
    "    plt.fill_between(range(num_generations), best_fitnesses_overall - std_fitnesses, best_fitnesses_overall + std_fitnesses, color='blue', alpha=0.2, label=\"Std Dev Range\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness Score\")\n",
    "    plt.title(f\"{algorithm.__name__}: Fitness Evolution in {scenario}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return best_overall_weights, best_overall_fitness, best_fitnesses_overall, mean_fitnesses, mean_execution_time, std_fitnesses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/100, Fitness: -0.06929301204140781\n",
      "Generation 2/100, Fitness: -0.06772797986342216\n",
      "Generation 3/100, Fitness: 0.010921709899752996\n",
      "Generation 4/100, Fitness: -0.07362099703432512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m random_weights \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m brain\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Evaluate the fitness of the current weights\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m fitness \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Check if the current weights are the best so far\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitness \u001b[38;5;241m>\u001b[39m best_fitness:\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mevaluate_fitness\u001b[1;34m(weights, view)\u001b[0m\n\u001b[0;32m     35\u001b[0m t_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(STEPS):  \n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Update actuation before stepping\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     action \u001b[38;5;241m=\u001b[39m brain(state_tensor)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;66;03m# Get action\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m view:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_GENERATIONS = 100  # Number of generations to evolve\n",
    "STEPS = 500\n",
    "SCENARIO = 'DownStepper-v0'\n",
    "# SEED = random.randint(0, 10000)\n",
    "# np.random.seed(SEED)\n",
    "# random.seed(SEED)\n",
    "\n",
    "\n",
    "robot_structure = np.array([ \n",
    "[1,3,1,0,0],\n",
    "[4,1,3,2,2],\n",
    "[3,4,4,4,4],\n",
    "[3,0,0,3,2],\n",
    "[0,0,0,0,2]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "connectivity = get_full_connectivity(robot_structure)\n",
    "env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "sim = env.sim\n",
    "input_size = env.observation_space.shape[0]  # Observation size\n",
    "output_size = env.action_space.shape[0]  # Action size\n",
    "\n",
    "brain = NeuralController(input_size, output_size)\n",
    "\n",
    "# ---- FITNESS FUNCTION ----\n",
    "def evaluate_fitness(weights, view=False):\n",
    "        set_weights(brain, weights)  # Load weights into the network\n",
    "        env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "        sim = env\n",
    "        viewer = EvoViewer(sim)\n",
    "        viewer.track_objects('robot')\n",
    "        state = env.reset()[0]  # Get initial state\n",
    "        t_reward = 0\n",
    "        for t in range(STEPS):  \n",
    "            # Update actuation before stepping\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # Convert to tensor\n",
    "            action = brain(state_tensor).detach().numpy().flatten() # Get action\n",
    "            if view:\n",
    "                viewer.render('screen') \n",
    "            state, reward, terminated, truncated, info = env.step(action)\n",
    "            t_reward += reward\n",
    "            if terminated or truncated:\n",
    "                env.reset()\n",
    "                break\n",
    "\n",
    "        viewer.close()\n",
    "        env.close()\n",
    "        return t_reward \n",
    "\n",
    "\n",
    "# ---- RANDOM SEARCH ALGORITHM ----\n",
    "best_fitness = -np.inf\n",
    "best_weights = None\n",
    "\n",
    "for generation in range(NUM_GENERATIONS):\n",
    "    # Generate random weights for the neural network\n",
    "    random_weights = [np.random.randn(*param.shape) for param in brain.parameters()]\n",
    "    \n",
    "    # Evaluate the fitness of the current weights\n",
    "    fitness = evaluate_fitness(random_weights)\n",
    "    \n",
    "    # Check if the current weights are the best so far\n",
    "    if fitness > best_fitness:\n",
    "        best_fitness = fitness\n",
    "        best_weights = random_weights\n",
    "    \n",
    "    print(f\"Generation {generation + 1}/{NUM_GENERATIONS}, Fitness: {fitness}\")\n",
    "\n",
    "# Set the best weights found\n",
    "set_weights(brain, best_weights)\n",
    "print(f\"Best Fitness: {best_fitness}\")\n",
    "\n",
    "\n",
    "# ---- VISUALIZATION ----\n",
    "def visualize_policy(weights):\n",
    "    set_weights(brain, weights)  # Load weights into the network\n",
    "    env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "    sim = env.sim\n",
    "    viewer = EvoViewer(sim)\n",
    "    viewer.track_objects('robot')\n",
    "    state = env.reset()[0]  # Get initial state\n",
    "    for t in range(STEPS):  \n",
    "        # Update actuation before stepping\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # Convert to tensor\n",
    "        action = brain(state_tensor).detach().numpy().flatten() # Get action\n",
    "        viewer.render('screen') \n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            env.reset()\n",
    "            break\n",
    "\n",
    "    viewer.close()\n",
    "    env.close()\n",
    "i = 0\n",
    "while i < 10:\n",
    "    visualize_policy(best_weights)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- HYPERPARAMETERS ----\n",
    "MU = 20               # Number of parents\n",
    "LAMBDA = 20           # Number of offspring per generation\n",
    "NUM_GENERATIONS = 100  # Number of generations\n",
    "MUTATION_STD = 0.1    # Standard deviation for Gaussian mutation\n",
    "STEPS = 500\n",
    "SCENARIO = 'DownStepper-v0'\n",
    "SEED = 42             # Não é suposto não termos seed fixa??\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ---- ENVIRONMENT SETUP ----\n",
    "robot_structure = np.array([\n",
    "    [1, 3, 1, 0, 0],\n",
    "    [4, 1, 3, 2, 2],\n",
    "    [3, 4, 4, 4, 4],\n",
    "    [3, 0, 0, 3, 2],\n",
    "    [0, 0, 0, 0, 2]\n",
    "])\n",
    "\n",
    "connectivity = get_full_connectivity(robot_structure)\n",
    "env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "sim = env.sim\n",
    "input_size = env.observation_space.shape[0]  # Observation size\n",
    "output_size = env.action_space.shape[0]  # Action size\n",
    "\n",
    "# Initialize neural network\n",
    "brain = NeuralController(input_size, output_size)\n",
    "\n",
    "# ---- FITNESS FUNCTION ----\n",
    "def evaluate_fitness(weights, view=False):\n",
    "    \"\"\"Evaluates the neural network controller's fitness.\"\"\"\n",
    "    set_weights(brain, weights)  # Load weights into the network\n",
    "    env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "    sim = env.sim\n",
    "    viewer = EvoViewer(sim)\n",
    "    viewer.track_objects('robot')\n",
    "    \n",
    "    state = env.reset()[0]\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(STEPS):\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        action = brain(state_tensor).detach().numpy().flatten()\n",
    "        \n",
    "        if view:\n",
    "            viewer.render('screen')\n",
    "\n",
    "        state, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    viewer.close()\n",
    "    env.close()\n",
    "    return total_reward\n",
    "\n",
    "# ---- INITIALIZATION ----\n",
    "def initialize_population():\n",
    "    \"\"\"Initialize the population with random weights.\"\"\"\n",
    "    return [[np.random.randn(*param.shape) for param in brain.parameters()] for _ in range(MU)]\n",
    "\n",
    "def mutate(parent):\n",
    "    \"\"\"Mutate an individual by adding Gaussian noise to weights.\"\"\"\n",
    "    return [w + MUTATION_STD * np.random.randn(*w.shape) for w in parent]\n",
    "\n",
    "# ---- (μ + λ) EVOLUTION STRATEGY ----\n",
    "def evolution_strategy():\n",
    "    \"\"\"Run the (μ + λ) Evolution Strategy to optimize the neural controller.\"\"\"\n",
    "    population = initialize_population()\n",
    "    best_fitness_scores = []\n",
    "    mean_fitness_scores = []\n",
    "    std_fitness_scores = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for generation in range(NUM_GENERATIONS):\n",
    "        # Evaluate fitness of current population\n",
    "        fitnesses = np.array([evaluate_fitness(ind) for ind in population])\n",
    "\n",
    "        # Store statistics\n",
    "        best_fitness_scores.append(np.max(fitnesses))\n",
    "        mean_fitness_scores.append(np.mean(fitnesses))\n",
    "        std_fitness_scores.append(np.std(fitnesses))\n",
    "\n",
    "        # Generate λ offspring by mutating random parents\n",
    "        offspring = [mutate(random.choice(population)) for _ in range(LAMBDA)]\n",
    "        offspring_fitnesses = np.array([evaluate_fitness(ind) for ind in offspring])\n",
    "\n",
    "        # Combine parents and offspring\n",
    "        combined_population = population + offspring\n",
    "        combined_fitnesses = np.concatenate((fitnesses, offspring_fitnesses))\n",
    "\n",
    "        # Select the top μ individuals for the next generation\n",
    "        top_indices = np.argsort(combined_fitnesses)[-MU:]\n",
    "        population = [combined_population[i] for i in top_indices]\n",
    "\n",
    "        print(f\"Generation {generation + 1}: Best Fitness = {best_fitness_scores[-1]:.3f}, Mean Fitness = {mean_fitness_scores[-1]:.3f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Get the best individual\n",
    "    best_idx = np.argmax(fitnesses)\n",
    "    best_weights = population[best_idx]\n",
    "    best_fitness = fitnesses[best_idx]\n",
    "\n",
    "    return best_weights, best_fitness, best_fitness_scores, mean_fitness_scores, execution_time, std_fitness_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
