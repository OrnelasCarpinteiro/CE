{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/100, Fitness: -0.06929301204140781\n",
      "Generation 2/100, Fitness: -0.06772797986342216\n",
      "Generation 3/100, Fitness: 0.010921709899752996\n",
      "Generation 4/100, Fitness: -0.07362099703432512\n",
      "Generation 5/100, Fitness: 0.07389050288225579\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m random_weights \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m brain\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Evaluate the fitness of the current weights\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m fitness \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Check if the current weights are the best so far\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitness \u001b[38;5;241m>\u001b[39m best_fitness:\n",
      "Cell \u001b[1;32mIn[1], line 47\u001b[0m, in \u001b[0;36mevaluate_fitness\u001b[1;34m(weights, view)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(STEPS):  \n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Update actuation before stepping\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mbrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;66;03m# Get action\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m view:\n\u001b[0;32m     49\u001b[0m         viewer\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\CE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\CE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\CE\\Project\\students\\neural_controller.py:11\u001b[0m, in \u001b[0;36mNeuralController.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Activation function\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)  \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtanh(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\CE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\CE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\CE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from evogym.envs import *\n",
    "from evogym import EvoViewer, get_full_connectivity\n",
    "from neural_controller import *\n",
    "\n",
    "\n",
    "NUM_GENERATIONS = 100  # Number of generations to evolve\n",
    "STEPS = 500\n",
    "SCENARIO = 'DownStepper-v0'\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "robot_structure = np.array([ \n",
    "[1,3,1,0,0],\n",
    "[4,1,3,2,2],\n",
    "[3,4,4,4,4],\n",
    "[3,0,0,3,2],\n",
    "[0,0,0,0,2]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "connectivity = get_full_connectivity(robot_structure)\n",
    "env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "sim = env.sim\n",
    "input_size = env.observation_space.shape[0]  # Observation size\n",
    "output_size = env.action_space.shape[0]  # Action size\n",
    "\n",
    "brain = NeuralController(input_size, output_size)\n",
    "\n",
    "# ---- FITNESS FUNCTION ----\n",
    "def evaluate_fitness(weights, view=False):\n",
    "        set_weights(brain, weights)  # Load weights into the network\n",
    "        env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "        sim = env\n",
    "        viewer = EvoViewer(sim)\n",
    "        viewer.track_objects('robot')\n",
    "        state = env.reset()[0]  # Get initial state\n",
    "        t_reward = 0\n",
    "        for t in range(STEPS):  \n",
    "            # Update actuation before stepping\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # Convert to tensor\n",
    "            action = brain(state_tensor).detach().numpy().flatten() # Get action\n",
    "            if view:\n",
    "                viewer.render('screen') \n",
    "            state, reward, terminated, truncated, info = env.step(action)\n",
    "            t_reward += reward\n",
    "            if terminated or truncated:\n",
    "                env.reset()\n",
    "                break\n",
    "\n",
    "        viewer.close()\n",
    "        env.close()\n",
    "        return t_reward \n",
    "\n",
    "\n",
    "# ---- RANDOM SEARCH ALGORITHM ----\n",
    "best_fitness = -np.inf\n",
    "best_weights = None\n",
    "\n",
    "for generation in range(NUM_GENERATIONS):\n",
    "    # Generate random weights for the neural network\n",
    "    random_weights = [np.random.randn(*param.shape) for param in brain.parameters()]\n",
    "    \n",
    "    # Evaluate the fitness of the current weights\n",
    "    fitness = evaluate_fitness(random_weights)\n",
    "    \n",
    "    # Check if the current weights are the best so far\n",
    "    if fitness > best_fitness:\n",
    "        best_fitness = fitness\n",
    "        best_weights = random_weights\n",
    "    \n",
    "    print(f\"Generation {generation + 1}/{NUM_GENERATIONS}, Fitness: {fitness}\")\n",
    "\n",
    "# Set the best weights found\n",
    "set_weights(brain, best_weights)\n",
    "print(f\"Best Fitness: {best_fitness}\")\n",
    "\n",
    "\n",
    "# ---- VISUALIZATION ----\n",
    "def visualize_policy(weights):\n",
    "    set_weights(brain, weights)  # Load weights into the network\n",
    "    env = gym.make(SCENARIO, max_episode_steps=STEPS, body=robot_structure, connections=connectivity)\n",
    "    sim = env.sim\n",
    "    viewer = EvoViewer(sim)\n",
    "    viewer.track_objects('robot')\n",
    "    state = env.reset()[0]  # Get initial state\n",
    "    for t in range(STEPS):  \n",
    "        # Update actuation before stepping\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # Convert to tensor\n",
    "        action = brain(state_tensor).detach().numpy().flatten() # Get action\n",
    "        viewer.render('screen') \n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            env.reset()\n",
    "            break\n",
    "\n",
    "    viewer.close()\n",
    "    env.close()\n",
    "i = 0\n",
    "while i < 10:\n",
    "    visualize_policy(best_weights)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
